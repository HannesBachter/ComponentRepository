//--------------------------------------------------------------------------
// Code generated by the SmartSoft MDSD Toolchain
// The SmartSoft Toolchain has been developed by:
//  
// Service Robotics Research Center
// University of Applied Sciences Ulm
// Prittwitzstr. 10
// 89075 Ulm (Germany)
//
// Information about the SmartSoft MDSD Toolchain is available at:
// www.servicerobotik-ulm.de
//
// This file is generated once. Modify this file to your needs. 
// If you want the toolchain to re-generate this file, please 
// delete it before running the code generator.
//--------------------------------------------------------------------------

//------------------------------------------------------------------------
//
//  Copyright (C) 2018 Nayabrasul Shaik, Matthias Rollenhagen
//
//        shaik@hs-ulm.de, rollenhagen@hs-ulm.de
//
//        Christian Schlegel (schlegel@hs-ulm.de)
//        University of Applied Sciences
//        Prittwitzstr. 10
//        89075 Ulm (Germany)
//
//  This file is part of the "SmartLaserFromRGBDServer component".
//
//  The method for converting 3D pointcloud to 2D laserscan is based on Mobile Robot Programming Toolkit (MRPT), http://www.mrpt.org/
//  https://github.com/MRPT/mrpt/blob/1371504fd3fdb891b92e80aa53eb26c4b33015cd/libs/obs/src/CObservation3DRangeScan.cpp
//--------------------------------------------------------------------------

//------------------------------------------------------------------------
//  For License : https://www.mrpt.org/License/
//  Copyright (c) 2005-2014, Individual contributors, see AUTHORS file
//  Copyright (c) 2005-2014, MAPIR group, University of Malaga
//  Copyright (c) 2012-2014, University of Almeria
//  All rights reserved.

//  Redistribution and use in source and binary forms, with or without
//  modification, are permitted provided that the following conditions are
//  met:
//  * Redistributions of source code must retain the above copyright
//        notice, this list of conditions and the following disclaimer.
//   * Redistributions in binary form must reproduce the above copyright
//        notice, this list of conditions and the following disclaimer in the
//        documentation and/or other materials provided with the distribution.
//   * Neither the name of the copyright holders nor the
//        names of its contributors may be used to endorse or promote products
//        derived from this software without specific prior written permission.

//  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
//  'AS IS' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
//  TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
//  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS BE LIABLE
//  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
//  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
//    SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
//  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
//  STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
//  ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
//  POSSIBILITY OF SUCH DAMAGE.
//--------------------------------------------------------------------------

#include "LaserTask.hh"
#include "ComponentLaserFromRGBDServer.hh"

#include <mrpt/gui/CDisplayWindow3D.h>
#include <mrpt/system/filesystem.h>
#include <mrpt/utils/CTicTac.h>
#include <mrpt/utils/CConfigFile.h>
#include <mrpt/opengl/CPointCloudColoured.h>
#include <mrpt/opengl/CPlanarLaserScan.h>
#include <mrpt/opengl/CFrustum.h>
#include <mrpt/opengl/CGridPlaneXY.h>
#include <mrpt/opengl/stock_objects.h>
#include <EulerTransformationMatrices.hh>
#include <Eigen/src/Core/Matrix.h>
#include <Eigen/src/Core/MatrixBase.h>
#include <mrpt/poses/CPose3D.h>
#include <mrpt/math.h>
#include <mrpt/utils.h>

#include <iostream>
#include <algorithm>
#include <set>
#include <cmath>
#include <vector>
#include <limits>


#define STOP while (std::cin.get() != '\n');
#define DEGTORAD(x) x*3.141592/180
#define RADTODEG(x) x*180/3.141592

#include <iostream>

LaserTask::LaserTask(SmartACE::SmartComponent *comp) 
:	LaserTaskCore(comp)
{
	std::cout << "constructor LaserTask\n";
	first_image_flag =true;
}
LaserTask::~LaserTask() 
{
	std::cout << "destructor LaserTask\n";
}



int LaserTask::on_entry()
{
	ParameterStateStruct global_state = COMP->getGlobalState();
	min_dist = global_state.getLaser_generator().getMin_range();
    max_dist = global_state.getLaser_generator().getMax_range();
    vertical_view = global_state.getLaser_generator().getVertical_fov(); //  degrees of vertical view
    rgbd_source = global_state.getLaser_generator().getRgbd_source(); // source of rgbd image
    angle_resolution = global_state.getLaser_generator().getAngle_resolution(); // angular resolution

    if(angle_resolution<DEGTORAD(0.5))
    	angle_resolution = DEGTORAD(0.5);

	std::cout << "[LaserTask] Initializing ..." << std::endl;

	return 0;
}
int LaserTask::on_execute()
{
	mrpt::utils::CTicTac stopwatch;

	stopwatch.Tic();

	// this method is called from an outside loop,
	// hence, NEVER use an infinite loop (like "while(1)") here inside!!!
	// also do not use blocking calls which do not result from smartsoft kernel

		// wait for scan (PushNewest)
		status = COMP->rgbdClient->getUpdateWait(rgbd_scan);

		if (status != Smart::SMART_OK) {

			std::cout << "blocking wait  status " << Smart::StatusCodeConversion(status) << " not ok => retry ..." << std::endl;
		}
		else
		{
			//Process RealSense Data
			if(true!=rgbd_scan.getIs_valid())
			{
				std::cout <<"RealSense Image data is INVALID" << std::endl;
			} else {

				if(first_image_flag)
				{
					read_intrinsics_extrinsics(rgbd_scan);
					init_laser_generation();
				}
				//Convert range image into 2D laser
				realsense_to_laserscan(rgbd_scan, laser_scan);

				//set basestate
				CommBasicObjects::CommBaseState base_state = rgbd_scan.getBase_state();

				//std::cout<<"odom pose: "<<rgbd_scan.getBase_state().get_base_raw_position().get_x(1)<<" "
				//					                     <<rgbd_scan.getBase_state().get_base_raw_position().get_y(1)<<" "
				//					                     <<rgbd_scan.getBase_state().get_base_raw_position().get_base_azimuth()<<std::endl;


				laser_scan.setBase_state(base_state);
				CommBasicObjects::CommPose3d base_pose = base_state.getBasePose().getPose3D();

				CommBasicObjects::CommPose3d sensor_pose(rgbd_scan.getSensor_pose());
				//laser_scan.set_sensor_pose(sensor_pose);
				laser_scan.set_sensor_pose(CommBasicObjects::CommPose3d(sensor_pose.get_x(),sensor_pose.get_y(),sensor_pose.get_z(),0,0,0));

				// set robot scanner position
				double x = sensor_pose.get_x();
				double y = sensor_pose.get_y();
				double z = sensor_pose.get_z();
				double azimuth = sensor_pose.get_azimuth();
				double elevation = sensor_pose.get_elevation();
				double roll = sensor_pose.get_roll();
				arma::mat mat_sensor;

				EulerTransformationMatrices::create_zyx_matrix(x, y, z, azimuth, elevation, roll, mat_sensor);

				// set world scanner position
				double base_x = 0;
				double base_y = 0;
				double base_z = 0;
				double base_a = 0;
				arma::mat mat_base(4, 4);

				base_x = base_state.get_base_position().get_x();
				base_y = base_state.get_base_position().get_y();
				base_z = base_state.get_base_position().get_z();
				if (COMP->getGlobalState().getScanner().getOn_turret()) {
					//base_a = base_state.get_base_position().get_turret_alpha();
				} else {
					base_a = base_state.get_base_position().get_base_azimuth();
				}

				EulerTransformationMatrices::create_zyx_matrix(base_x, base_y, base_z, base_a, 0, 0, mat_base);
				arma::mat mat_world = mat_base * mat_sensor;
				CommBasicObjects::CommPose3d world_pose(mat_world);



				double sensor_yaw = sensor_pose.get_azimuth(), sensor_pitch = sensor_pose.get_elevation(), sensor_roll = sensor_pose.get_roll();
				double sensor_x = sensor_pose.getPosition().getX() / 1000, sensor_y = sensor_pose.getPosition().getY() / 1000, sensor_z = sensor_pose.getPosition().getZ() / 1000;

				double bbase_yaw = base_pose.get_azimuth(), bbase_pitch = base_pose.get_elevation(), bbase_roll = base_pose.get_roll();
				double bbase_x = base_pose.getPosition().getX() / 1000, bbase_y = base_pose.getPosition().getY() / 1000, bbase_z = base_pose.getPosition().getZ() / 1000;

				laser_scan.set_scanner_x(world_pose.get_x());
				laser_scan.set_scanner_y(world_pose.get_y());
				laser_scan.set_scanner_z(world_pose.get_z());

				laser_scan.set_scanner_azimuth(world_pose.get_azimuth());
				laser_scan.set_scanner_elevation(world_pose.get_elevation());
				laser_scan.set_scanner_roll(world_pose.get_roll());

				if (COMP->getGlobalState().getServices().getActivate_push_newest()) {
					Smart::StatusCode push_status = COMP->laserPushNewestServer->put(laser_scan);
					if (push_status != Smart::SMART_OK) {
						std::cerr << "[LaserTask] WARNING: error on push (" << Smart::StatusCodeConversion(push_status)
						<< ")" << std::endl;
					}
				}
				// copy local scan to global scan
				SmartACE::SmartGuard scan_guard(COMP->ScanLock);
				COMP->global_scan = laser_scan;
				scan_guard.release();

				if (COMP->getGlobalState().getScanner().getVerbose())
				{
					const unsigned int index = laser_scan.get_scan_size();
					//std::cout << "[LaserTask] Scan " << laser_scan.get_scan_update_count() << " sent." << " Scan Size " << index << "/"
					//<< "Max Distance = " << laser_scan.get_max_distance() << "mm" << std::endl;

				}

			}
		}


	double detection_time = stopwatch.Tac();
	std::cout << " Current Frequency: " << 1.0f/detection_time << "Hz" << std::endl;

	return 0;

}
int LaserTask::on_exit()
{
	std::cout << "[LaserTask] Disconnect from laser" << std::endl;
	return 0;
}

bool LaserTask::realsense_to_laserscan(DomainVision::CommRGBDImage &rgbd_scan, CommBasicObjects::CommMobileLaserScan& laser_scan)
{

	//DomainVision::CommVideoImage comm_rgb_image = rgbd_scan.getColor_image();
	DomainVision::CommDepthImage comm_depth_image = rgbd_scan.getDepth_image();
	std::fill( floor_mask.begin(), floor_mask.end(), false);


	mrpt::utils::CTicTac stopwatch;

	stopwatch.Tic();
	detect_floor(rgbd_scan, floor_mask); // find the points correspond to floor

	double detection_time = stopwatch.Tac();
		//std::cout << "[detect_floor] Detection time: " << detection_time << "s" << std::endl;




	// Convert to scan:
	// set scan header
	laser_scan.set_scan_time_stamp(CommBasicObjects::CommTimeStamp::now());
	laser_scan.set_scan_update_count(rgbd_scan.getSeq_count());
	laser_scan.set_scan_length_unit(1.0);
	laser_scan.set_scan_double_field_of_view(RADTODEG(start_angle),
			RADTODEG(angle_resolution)); // smartsoft needs degrees multiplied by 100 i.e 1 deg = 100
	laser_scan.set_max_distance(max_dist); //in mm
	laser_scan.set_min_distance(min_dist); //in mm

	laser_scan.set_max_scan_size(nLaserRays);
	laser_scan.set_scan_size(nLaserRays);
	laser_scan.set_scan_valid(true);

	laser_ray_distances.clear();


	stopwatch.Tic();
	find_depth_distances(comm_depth_image, laser_ray_distances);
	double detection_time1 = stopwatch.Tac();
			//std::cout << "[find_depth_distances] Detection time: " << detection_time1 << "s" << std::endl;



	stopwatch.Tic();
	set_laser_ray_distances(laser_scan, laser_ray_distances);
	double detection_time2 = stopwatch.Tac();
			//std::cout << "[set_laser_ray_distances] Detection time: " << detection_time2 << "s" << std::endl;

	return true;

}

void LaserTask::init_laser_generation()
{
	// do these calculation only once
	//These view angles calculations are from Realsense lib
	hfov_rad = std::atan2(depth_intrinsics.cx + 0.5f, depth_intrinsics.fx) + std::atan2(depth_intrinsics.cols - (depth_intrinsics.cx + 0.5f), depth_intrinsics.fx);
	vfov_rad = std::atan2(depth_intrinsics.cy + 0.5f, depth_intrinsics.fy) + std::atan2(depth_intrinsics.rows - (depth_intrinsics.cy + 0.5f), depth_intrinsics.fy);


	//MRPT calculate FOV
	// (Imagine the camera seen from above to understand this geometry)
//	const double real_FOV_left = std::atan2(depth_intrinsics.cx, depth_intrinsics.fx);
//	const double real_FOV_right = std::atan2(depth_intrinsics.cols - 1 - depth_intrinsics.cx, depth_intrinsics.fx);
//
//	// FOV of the equivalent "fake" "laser scanner":
//	hfov_rad = 2. * std::max(real_FOV_left, real_FOV_right);

    //nLaserRays           = static_cast<size_t>(depth_intrinsics.cols * 1.5f); //1.2f is default over sampling ratio
    //angle_resolution     = (double)hfov_rad/(nLaserRays-1);

	angle_resolution     = DEGTORAD(0.5);
	nLaserRays           = hfov_rad/angle_resolution;
	start_angle          = (double)-1.0f*hfov_rad*0.5f;

	vert_ang_tan.resize(depth_intrinsics.rows);
	for (size_t r = 0; r < depth_intrinsics.rows; r++){
		vert_ang_tan[r] = static_cast<float>((depth_intrinsics.cy - r) / depth_intrinsics.fy);
	}

	vertical_view = vfov_rad*2.0f; // consider all the vertical fov

	tan_min = -std::tan(vertical_view*0.5f); // tan needs radians
	tan_max =  std::tan(vertical_view*0.5f);


//	tan_min =  std::tan(-1*std::numeric_limits<double>::infinity());
//	tan_max =  std::tan(std::numeric_limits<double>::infinity());




	//TODO calculate floor distancen using camera pose
	camera_height_from_floor = camera_height_from_floor_meters();

	depth_data_type = rgbd_scan.getDepth_image().getFormat();

	floor_mask.resize(depth_intrinsics.rows*depth_intrinsics.cols);
	std::fill( floor_mask.begin(), floor_mask.end(), false);

	display_parameters();

	first_image_flag= false;

}

double LaserTask::camera_height_from_floor_meters()
{
	return 0.05;

}

double LaserTask::pi_to_pi(double angle) {
	angle += M_PI;
	double ret_angle = fmod(angle, 2* M_PI );

	if (angle < 0)
		ret_angle += 2* M_PI ;

	ret_angle -= M_PI;

	return ret_angle;
}

void LaserTask::display_parameters()
{
	    std::cout <<"-----------------------------------------------------------------"<<std::endl;
		std::cout <<std::setw(40)<<"Laser Parameters"<<std::endl;
		std::cout <<"-----------------------------------------------------------------"<<std::endl;
		std::cout <<std::setw(25)<<  "Number of rays"    <<" = " << nLaserRays<<std::endl;
		std::cout <<std::setw(25)<<  "Horizontal Field of View"  <<" = " << RADTODEG(hfov_rad)<< " degrees"<<std::endl;
		std::cout <<std::setw(25)<<  "Vertical Field of View"  <<" = " << RADTODEG(vfov_rad)<< " degrees"<<std::endl;
		std::cout <<std::setw(25)<<  "Angle resolution"  <<" = " << RADTODEG(angle_resolution)<< " degrees"<<std::endl;
		std::cout <<std::setw(25)<<  "Max distance"      <<" = " << max_dist/1000.0<< " meters"<<std::endl;
		std::cout <<std::setw(25)<<  "Min distance"      <<" = " << min_dist/1000.0<< " meters"<<std::endl;
		std::cout <<std::setw(25)<<  "Floor distance"    <<" = " << camera_height_from_floor<< " meters"<<std::endl;
		std::cout <<std::setw(25)<<  "Start_angle"       <<" = " << RADTODEG(start_angle) <<std::endl;
		std::cout <<"-----------------------------------------------------------------"<<std::endl;
}

/*Convert image pixel to real world point
 * equations and functions are similar to realsense library
 * https://github.com/IntelRealSense/librealsense/blob/master/include/librealsense2/rsutil.h
 *
 * */
void LaserTask::deproject(const st_intrinsics& intrinsics, const uint32_t& r, const uint32_t& c, const float &depth_val_meters, float &out_x, float &out_y, float &out_z)
{
	float x = (c - intrinsics.cx) / intrinsics.fx;
	float y = (r - intrinsics.cy) / intrinsics.fy;
	if(intrinsics.distortion_model == DomainVision::ImageDistortionModel::BROWN_CONRADY)
	{
		float r2  = x*x + y*y;
		float f =    1 + intrinsics.distortion_coeffs[0]*r2    + intrinsics.distortion_coeffs[1]*r2*r2 + intrinsics.distortion_coeffs[4]*r2*r2*r2;
		float ux = x*f + 2*intrinsics.distortion_coeffs[2]*x*y + intrinsics.distortion_coeffs[3]*(r2 + 2*x*x);
		float uy = y*f + 2*intrinsics.distortion_coeffs[3]*x*y + intrinsics.distortion_coeffs[2]*(r2 + 2*y*y);
		x = ux;
		y = uy;
		//std::cout << "distortion in de projection" <<std::endl;
	}
	out_x = depth_val_meters * x;
	out_y = depth_val_meters * y;
	out_z = depth_val_meters;

}
/*Convert real world point to image pixel*/
void LaserTask::project(const st_intrinsics& intrinsics, uint32_t& out_r, uint32_t& out_c, const float &in_x, const float &in_y, const float &in_z)
{

	float x = in_x/in_z;
	float y = in_y/in_z;


	if(intrinsics.distortion_model == DomainVision::ImageDistortionModel::BROWN_CONRADY)
	{
		float r2  = x*x + y*y;
		float f = 1 + intrinsics.distortion_coeffs[0]*r2 + intrinsics.distortion_coeffs[1]*r2*r2 + intrinsics.distortion_coeffs[4]*r2*r2*r2;
		x *= f;
		y *= f;
		float dx = x + 2*intrinsics.distortion_coeffs[2]*x*y + intrinsics.distortion_coeffs[3]*(r2 + 2*x*x);
		float dy = y + 2*intrinsics.distortion_coeffs[3]*x*y + intrinsics.distortion_coeffs[2]*(r2 + 2*y*y);
		x = dx;
		y = dy;
	}

	out_c =  x * intrinsics.fx + intrinsics.cx;
    out_r =  y * intrinsics.fy + intrinsics.cy;
}

void LaserTask::transform (const st_extrinsics& extrinsics, float &x, float &y, float &z)
{

	float from_point_x = x;
	float from_point_y = y;
	float from_point_z = z;


	float to_point_x = extrinsics.rotation[0] * from_point_x + extrinsics.rotation[3] * from_point_x + extrinsics.rotation[6] * from_point_x + extrinsics.translation[0];
	float to_point_y = extrinsics.rotation[1] * from_point_y + extrinsics.rotation[4] * from_point_y + extrinsics.rotation[7] * from_point_y + extrinsics.translation[1];
	float to_point_z = extrinsics.rotation[2] * from_point_z + extrinsics.rotation[5] * from_point_z + extrinsics.rotation[8] * from_point_z + extrinsics.translation[2];

	x= to_point_x;
	y= to_point_y;
	z= to_point_z;

	//std::cout <<"from: " <<from_point_x <<", "<<from_point_y <<", "<<from_point_z <<", "<<"   To: " <<to_point_x <<", "<<to_point_y <<", "<<to_point_z <<", "<<std::endl;

}

void LaserTask::calcPointXYZ (const uint32_t& r, const uint32_t& c, const float &depth_val_meters, float &x, float &y, float &z,
		                             const st_intrinsics& intrinsics, const st_extrinsics& extrinsics)
{

  //depth value is not valid
  if(std::isnan(depth_val_meters) || depth_val_meters <= 0.001)
  {
    //depth value is not valid
	const float bad_point = std::numeric_limits<float>::quiet_NaN();
    x = y = z = bad_point;
  }
  else
  {
	  // find corresponding x,y,z of give depth pixel and depth value
	  deproject(intrinsics,r, c, depth_val_meters, x, y, z);
	  // transform x,y,z into rgb coordinate system using extrinsics
	  //transform(extrinsics, x, y, z);
  }
}

void LaserTask::detect_floor (DomainVision::CommRGBDImage& rgbd_scan, std::vector<bool>& floor_mask)
{

	DomainVision::CommDepthImage comm_depth_image = rgbd_scan.getDepth_image();

	// get depth data
	DomainVision::DepthFormatType depth_format = comm_depth_image.getFormat();
	uint32_t depth_width 							= comm_depth_image.getWidth();
	uint32_t depth_height 							= comm_depth_image.getHeight();

	float x_in_m, y_in_m, z_in_m;
	mrpt::utils::CTicTac stopwatch;
	stopwatch.Tic();
	CommBasicObjects::CommPose3d sensor_pose   = rgbd_scan.getSensor_pose();
	double sensor_yaw = sensor_pose.get_azimuth(), sensor_pitch = sensor_pose.get_elevation(), sensor_roll = sensor_pose.get_roll();
    double sensor_x = sensor_pose.getPosition().getX() / 1000, sensor_y = sensor_pose.getPosition().getY() / 1000, sensor_z = sensor_pose.getPosition().getZ() / 1000;
    mrpt::poses::CPose3D sensorPose_mrpt(sensor_x, sensor_y, sensor_z,sensor_yaw, sensor_pitch, sensor_roll);

    float max_distance_meters = max_dist/1000.0f;

	for (uint32_t depth_row = 0; depth_row < depth_height; ++depth_row) { //along y
		for (uint32_t depth_col = 0; depth_col < depth_width; ++depth_col) { //along x-axis


			float depth_meters = get_depth(comm_depth_image, depth_row, depth_col);


			if(depth_col<=25){  // 25 columns in 1280x720 depth image are invalid band
				floor_mask[depth_row*depth_width+depth_col] = true;
				continue;
			}

			if((std::isinf(depth_meters)) || (depth_meters != depth_meters)){
				floor_mask[depth_row*depth_width+depth_col] = true;
				continue;
			}

			if(depth_meters < 0.05 || depth_meters > max_distance_meters) // filter the invalid points
			{
				floor_mask[depth_row*depth_width+depth_col] = true;
				continue;
			}

            //find x, y, z for given depth pixel in rgb frame
			calcPointXYZ (depth_row, depth_col, depth_meters, x_in_m, y_in_m, z_in_m, depth_intrinsics, depth_to_color_extrinsics);


			if(std::isinf(x_in_m) || std::isinf(z_in_m) || std::isinf(y_in_m)){
				floor_mask[depth_row*depth_width+depth_col] = true;
				continue;
			}
			if(x_in_m != x_in_m || y_in_m != y_in_m || z_in_m != z_in_m){
				floor_mask[depth_row*depth_width+depth_col] = true;
				continue;
			}

			// convert x, y, z to robot frame
			mrpt::poses::CPoint3D point_in_realsense_frame(x_in_m, y_in_m, z_in_m);

			//mrpt::poses::CPoint3D point_in_robot_frame =transormPointToRobotCoord(point_in_realsense_frame,sensor_pose);
			mrpt::poses::CPoint3D point_in_robot_frame =  sensorPose_mrpt + point_in_realsense_frame;

			if(point_in_robot_frame.z() <camera_height_from_floor)// filter points related to floor
			{
				floor_mask[depth_row*depth_width+depth_col] = true;
			}

			}
	}

	double detection_time3 = stopwatch.Tac();
	//std::cout << "[loop] Detection time: " << detection_time3 << "s" << std::endl;

}
void LaserTask::read_intrinsics_extrinsics(const DomainVision::CommRGBDImage& rgbd_image)
{
	// get color intrinsics
	{
	DomainVision::CommVideoImage comm_rgb_image = rgbd_image.getColor_image();
	arma::mat comm_color_intrinsic = arma::zeros(4,4);
	comm_color_intrinsic = comm_rgb_image.get_intrinsic();

	color_intrinsics.fx 	= comm_color_intrinsic(0,0);
	color_intrinsics.fy 	= comm_color_intrinsic(1,1);
	color_intrinsics.cx 	= comm_color_intrinsic(0,2);
	color_intrinsics.cy 	= comm_color_intrinsic(1,2);
	color_intrinsics.cols 	= comm_rgb_image.getParameter().width;
	color_intrinsics.rows 	= comm_rgb_image.getParameter().height;
	color_intrinsics.distortion_model = comm_rgb_image.getDistortion_model();

	arma::mat comm_color_distortion = arma::zeros(1,5);

	comm_color_distortion = comm_rgb_image.get_distortion();
	color_intrinsics.distortion_coeffs[0] = comm_color_distortion(0,0);
	color_intrinsics.distortion_coeffs[1] = comm_color_distortion(0,1);
	color_intrinsics.distortion_coeffs[2] = comm_color_distortion(0,2);
	color_intrinsics.distortion_coeffs[3] = comm_color_distortion(0,3);
	color_intrinsics.distortion_coeffs[4] = comm_color_distortion(0,4);
	}

	// get depth intrinsics
	{

	DomainVision::CommDepthImage comm_depth_image = rgbd_image.getDepth_image();

	arma::mat comm_depth_intrinsic = arma::zeros(4,4);
	comm_depth_intrinsic = comm_depth_image.get_intrinsic();

	depth_intrinsics.fx 	= comm_depth_intrinsic(0,0);
	depth_intrinsics.fy 	= comm_depth_intrinsic(1,1);
	depth_intrinsics.cx 	= comm_depth_intrinsic(0,2);
	depth_intrinsics.cy 	= comm_depth_intrinsic(1,2);
	depth_intrinsics.cols 	= comm_depth_image.getWidth();
	depth_intrinsics.rows 	= comm_depth_image.getHeight();
	depth_intrinsics.distortion_model = comm_depth_image.getDistortion_model();

	arma::mat comm_depth_distortion = arma::zeros(1,5);

	comm_depth_distortion = comm_depth_image.get_distortion();
	depth_intrinsics.distortion_coeffs[0] = comm_depth_distortion(0,0);
	depth_intrinsics.distortion_coeffs[1] = comm_depth_distortion(0,1);
	depth_intrinsics.distortion_coeffs[2] = comm_depth_distortion(0,2);
	depth_intrinsics.distortion_coeffs[3] = comm_depth_distortion(0,3);
	depth_intrinsics.distortion_coeffs[4] = comm_depth_distortion(0,4);

    //get depth extrinsics
	arma::mat comm_depth_extrinsics = arma::zeros(1,12);
	comm_depth_extrinsics = comm_depth_image.get_extrinsic();

	depth_to_color_extrinsics.rotation[0] =     comm_depth_extrinsics(0,0);
	depth_to_color_extrinsics.rotation[1] =     comm_depth_extrinsics(0,1);
	depth_to_color_extrinsics.rotation[2] =     comm_depth_extrinsics(0,2);
	depth_to_color_extrinsics.rotation[3] =     comm_depth_extrinsics(0,3);
	depth_to_color_extrinsics.rotation[4] =     comm_depth_extrinsics(0,4);
	depth_to_color_extrinsics.rotation[5] =     comm_depth_extrinsics(0,5);
	depth_to_color_extrinsics.rotation[6] =     comm_depth_extrinsics(0,6);
	depth_to_color_extrinsics.rotation[7] =     comm_depth_extrinsics(0,7);
	depth_to_color_extrinsics.rotation[8] =     comm_depth_extrinsics(0,8);

	depth_to_color_extrinsics.translation[0] = comm_depth_extrinsics(0,9);
	depth_to_color_extrinsics.translation[1] = comm_depth_extrinsics(0,10);
	depth_to_color_extrinsics.translation[2] = comm_depth_extrinsics(0,11);
	}

}

void LaserTask::comm_depth_image_to_cv_mat(DomainVision::CommDepthImage& comm_depth_image, cv::Mat& depth_mat)
{
	const uint16_t* depth_data_uint16;
	const float* depth_data_float;
	DomainVision::DepthFormatType depth_format = comm_depth_image.getFormat();
	if(depth_format==DomainVision::DepthFormatType::UINT16)
	{
		//depth_data_uint16 = comm_depth_image.get_distances_data<const uint16_t*>();
		depth_data_uint16 = comm_depth_image.get_distances_uint16();

	}else if (depth_format==DomainVision::DepthFormatType::FLOAT)
	{
		depth_data_float = comm_depth_image.get_distances_float();

	}

	uint32_t depth_width   =  depth_intrinsics.cols;
	uint32_t depth_height  =  depth_intrinsics.rows;
	float pixel_meters;

	for (uint32_t depth_row = 0; depth_row < depth_height ; ++depth_row){//along y
		for (uint32_t depth_col = 0; depth_col < depth_width;++depth_col){//along x-axis

			pixel_meters = get_depth(comm_depth_image, depth_row, depth_col);

			uint8_t r = pixel_meters / 8* 255 ;
			uint8_t g = pixel_meters / 8* 255 ;
			uint8_t b = pixel_meters / 8* 255 ;

			depth_mat.at<cv::Vec3b>(depth_row, depth_col)[0]=g;
			depth_mat.at<cv::Vec3b>(depth_row, depth_col)[1]=g;
			depth_mat.at<cv::Vec3b>(depth_row, depth_col)[2]=b;


		}
	}


}

void LaserTask::find_depth_distances(DomainVision::CommDepthImage& comm_depth_image, std::deque<float>& laser_ray_distances)
{
	double current_angle = start_angle;

	const uint16_t* depth_data_uint16;
	const float* depth_data_float;
	if(depth_data_type==DomainVision::DepthFormatType::UINT16)
	{
		depth_data_uint16 = comm_depth_image.get_distances_uint16();
	}else if (depth_data_type==DomainVision::DepthFormatType::FLOAT)
	{
		depth_data_float = comm_depth_image.get_distances_float();
	}


	//int over_sampled_rays = nLaserRays*1.5;
	//double a_angle = hfov_rad/(over_sampled_rays-1);

	for (size_t i = 0; i < nLaserRays; i++, current_angle += angle_resolution) {
			// Equivalent column in the range image for the "i'th" ray:
			const double tan_ang = tan(current_angle);
			// make sure we don't go out of range (just in case):
			float max_v = std::max(0.0,
					depth_intrinsics.cx + depth_intrinsics.fx * tan_ang);
			float xcol = depth_intrinsics.cols - 1;// Column correspond to current angle
			const size_t c = std::min(max_v, xcol);
			bool any_valid = false;

			float closest_range_meters = max_dist / 1000.0f; //in meters
			float min_distance_meters = min_dist / 1000.0f; //in meters
			std::set<float> row_ordered_set;

			for (int r = 0; r < depth_intrinsics.rows; r++) {

				if (floor_mask[r * depth_intrinsics.cols + c] == true)  // dont process if it is floor or invalid
					continue;


				//float current_distance_meters = get_depth(comm_depth_image, r, c);
				float current_distance_meters =0.0;
				if(depth_data_type==DomainVision::DepthFormatType::UINT16)
				{
					const uint16_t depth_val_ptr = depth_data_uint16[r*depth_intrinsics.cols+c];

					current_distance_meters = depth_val_ptr/1000.0f;
				}else if(depth_data_type==DomainVision::DepthFormatType::FLOAT)
				{
					const float depth_val_ptr = depth_data_float[r*depth_intrinsics.cols+c];

					current_distance_meters= depth_val_ptr;
					//std::cout << " depth = " <<depth_meters<<std::endl;

				}else
				{
					std::cout << "Unknow Depth Format" <<std::endl;
					std::abort();
				}


				if (current_distance_meters < min_dist/1000.0 || current_distance_meters > max_dist/1000.0)
					continue;


				// All filters passed:
				const float this_point_tan = vert_ang_tan[r]* current_distance_meters;

				if (this_point_tan > tan_min && this_point_tan < tan_max)  // we  are considering all the rays
				{
					any_valid = true;
					row_ordered_set.insert(current_distance_meters);
				}
			}

			if (any_valid) // got a valid minimum depth from ranges of a row
			{


				for (auto it = row_ordered_set.begin(); it != row_ordered_set.end(); ++it) {

					//if ((*it) > min_dist / 1000) {

						float distance_meters = (*it);

						distance_meters = distance_meters * std::sqrt(1.0 + tan_ang * tan_ang);
				laser_ray_distances.push_front(distance_meters*1000);
						break;
					//}
				}


			}
			else // keeping default maximum value, very dangerous
			{
				laser_ray_distances.push_front(max_dist+ 100); // this will be invalid

			}
		}

	//std::cout << "size of laser ray distances = " << laser_ray_distances.size() << std::endl;
}

inline float LaserTask::get_depth(DomainVision::CommDepthImage& comm_depth_image, int row, int col)
{
	float current_distance_meters;

	if (depth_data_type == DomainVision::DepthFormatType::UINT16) {

		const uint16_t pixel = comm_depth_image.get_distance < uint16_t	> (col, row);
		current_distance_meters = pixel / 1000.0f;

	} else if (depth_data_type == DomainVision::DepthFormatType::FLOAT) {

		float pixel = comm_depth_image.get_distance<float>(col, row);

		current_distance_meters = pixel; //1000.0f;

	}

	return current_distance_meters;
}

void LaserTask::set_laser_ray_distances(CommBasicObjects::CommMobileLaserScan& laser_scan, std::deque<float>& laser_ray_distances)
{

	const int desiredScans = 1 + hfov_rad / angle_resolution;
	const int rangerScans = 1 + hfov_rad / angle_resolution;
    //std::cout << " desiredScans = " << desiredScans
	//	      << " rangerScans  = " << rangerScans<< std::endl;

	laser_scan.set_max_scan_size(desiredScans);

	//const int firstScanIndex = ((rangerScans - desiredScans) * 0.5)+25;
	const int firstScanIndex = ((rangerScans - desiredScans) * 0.5);
	int lastScanIndex = rangerScans - firstScanIndex-2;//-25; // 25 columns correspond to invalid depth band

	//std::cout << " firstScanIndex = " << firstScanIndex
	//		      << " lastScanIndex  = " << lastScanIndex<< std::endl;

	uint32_t num_valid_points = 0;
	for (int i = firstScanIndex; i < lastScanIndex; ++i) {
		const unsigned int dist = laser_ray_distances.at(i);
		if (dist >= min_dist && dist <= max_dist) {
			++num_valid_points;
		}
	}

	laser_scan.set_scan_size(num_valid_points);

	uint32_t valid_point_index = 0;
	for (int i = firstScanIndex; i < lastScanIndex; ++i) {
		const unsigned int dist = laser_ray_distances.at(i);
		if (dist >= min_dist && dist <= max_dist) {
			//this line will cut of the starting beam if the component is configures to provide smaller scans (less opening angle)
			laser_scan.set_scan_index(valid_point_index, i - firstScanIndex);
			laser_scan.set_scan_integer_distance(valid_point_index, dist);

			//std::cout << "valid point index, i-firstScanIndex " << valid_point_index << ", " << (i - firstScanIndex) << "  dist =  " << dist <<std::endl;
			++valid_point_index;
		}
	}

	laser_scan.set_scan_valid(true);
}
void LaserTask::find_depth_distances_debug(DomainVision::CommDepthImage& comm_depth_image, std::deque<float>& laser_ray_distances)
{
	double current_angle = start_angle;

	const uint16_t* depth_data_uint16;
	const float* depth_data_float;
	if(depth_data_type==DomainVision::DepthFormatType::UINT16)
	{
		depth_data_uint16 = comm_depth_image.get_distances_uint16();
	}else if (depth_data_type==DomainVision::DepthFormatType::FLOAT)
	{
		depth_data_float = comm_depth_image.get_distances_float();
	}

	for (size_t i = 0; i < nLaserRays; i++, current_angle += angle_resolution) {
		// Equivalent column in the range image for the "i'th" ray:
		const double tan_ang = tan(current_angle);
		// make sure we don't go out of range (just in case):
		float max_v = std::max(0.0,
				depth_intrinsics.cx + depth_intrinsics.fx * tan_ang);
		float xcol = depth_intrinsics.cols - 1;// Column correspond to current angle
		const size_t c = std::min(max_v, xcol);
		bool any_valid = false;

		float closest_range_meters = max_dist / 1000.0f; //in meters
		float min_distance_meters = min_dist / 1000.0f; //in meters
		std::multimap<float, std::pair<int, int>> row_ordered;

		for (int r = 0; r < depth_intrinsics.rows; r++) {

			float current_distance_meters =0.0;
			if(depth_data_type==DomainVision::DepthFormatType::UINT16)
			{
				const uint16_t depth_val_ptr = depth_data_uint16[r*depth_intrinsics.cols+c];

				current_distance_meters = depth_val_ptr/1000.0f;
			}else if(depth_data_type==DomainVision::DepthFormatType::FLOAT)
			{
				const float depth_val_ptr = depth_data_float[r*depth_intrinsics.cols+c];

				current_distance_meters= depth_val_ptr;
				//std::cout << " depth = " <<depth_meters<<std::endl;

			}else
			{
				std::cout << "Unknow Depth Format" <<std::endl;
				std::abort();
			}


			if (current_distance_meters < min_dist/1000.0 || current_distance_meters > max_dist/1000.0)
				continue;


			// All filters passed:
			const float this_point_tan = vert_ang_tan[r]* current_distance_meters;

			//std::cout << "this_point_tan = "<< this_point_tan << "  tan_min = "<< tan_min << "  tan_max = "<< tan_max <<std::endl;

			if (this_point_tan > tan_min && this_point_tan < tan_max)  // we  are considering all the rays
			{
				any_valid = true;
				row_ordered.insert(
						std::pair<float, std::pair<int, int>>(
								current_distance_meters, std::make_pair(r, c)));
			}
		}

		if (any_valid) // got a valid minimum depth from ranges of a row
		{
			//float distance_meters = (closest_range_meters)* std::sqrt(1.0 + tan_ang * tan_ang);

			for (auto it = row_ordered.begin(); it != row_ordered.end(); ++it) {

				if ((*it).first > min_dist / 1000) {

					float distance_meters = (*it).first;

					distance_meters = distance_meters * std::sqrt(1.0 + tan_ang * tan_ang);

					laser_ray_distances.push_front(distance_meters*1000);
					break;
				}
			}


		} else // keeping default maximum value, very dangerous
		{
			laser_ray_distances.push_front(max_dist); // this will be invalid
		}
	}  // end for columns
}

/**
 * Transforms the inserted point from sensor coordinate system
 * to robot coordinate system.
 */
mrpt::poses::CPoint3D LaserTask::transormPointToRobotCoord(const mrpt::poses::CPoint3D & point, CommBasicObjects::CommPose3d& sensor_pose) {

	double sensor_yaw = sensor_pose.get_azimuth(), sensor_pitch = sensor_pose.get_elevation(), sensor_roll = sensor_pose.get_roll();
	double sensor_x = sensor_pose.getPosition().getX() / 1000, sensor_y = sensor_pose.getPosition().getY() / 1000, sensor_z = sensor_pose.getPosition().getZ() / 1000;

	mrpt::poses::CPose3D sensorPose(sensor_x, sensor_y, sensor_z,sensor_yaw, sensor_pitch, sensor_roll);
	mrpt::poses::CPoint3D result =  sensorPose + point;

	return result;
}
